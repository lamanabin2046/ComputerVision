{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "247a31f5",
   "metadata": {},
   "source": [
    "# Tutorial: Image Annotation for Computer Vision\n",
    "\n",
    "- Annotation is the process of labeling images so machines can learn to “see” like humans.\n",
    "\n",
    "- It’s the ground truth used to train AI models in tasks such as object detection and segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38febb81",
   "metadata": {},
   "source": [
    "## Types of annotation\n",
    "\n",
    "- Bounding box \n",
    "- Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bf56a5",
   "metadata": {},
   "source": [
    "### Bounding Box\n",
    "\n",
    "- Definition: The simplest form of annotation. Draw a rectangle around the object of interest.\n",
    "\n",
    "- Use case: Object detection (e.g., detecting cats, cars, faces).\n",
    "\n",
    "- How it’s stored: Coordinates of top-left corner (x, y), plus width and height.\n",
    "\n",
    "- Advantages: Simple, fast, small annotation files.\n",
    "\n",
    "- Limitations: Doesn’t capture the exact shape of the object (lots of background included).\n",
    "\n",
    "#### Example:\n",
    "\n",
    " - A box drawn around a cat in an image.\n",
    "\n",
    "- Supported by formats: YOLO, COCO, Pascal VOC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d3d845",
   "metadata": {},
   "source": [
    "### Segmentation\n",
    "\n",
    "- Definition: More precise labeling, where each object is outlined by its exact shape.\n",
    "\n",
    "Types:\n",
    "\n",
    "- Polygonal segmentation: draw polygons around objects.\n",
    "\n",
    "- Pixel-wise segmentation (masking): each pixel is assigned a class label.\n",
    "\n",
    "- Use case: Semantic segmentation (road/lane markings), instance segmentation (detecting multiple objects of the same class).\n",
    "\n",
    "- How it’s stored: Polygons (list of points) or binary masks.\n",
    "\n",
    "- Advantages: Very accurate, useful for detailed tasks.\n",
    "\n",
    "- Limitations: Time-consuming, large annotation files.\n",
    "\n",
    "### Example:\n",
    "\n",
    "- Carefully outlining the cat’s ears, tail, and body instead of just using a rectangle.\n",
    "\n",
    "- Supported by formats: COCO, Pascal VOC (mask), LabelMe JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b64668e",
   "metadata": {},
   "source": [
    "![alt text](Data-Annotations.png \"Annotation Examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fda44b",
   "metadata": {},
   "source": [
    "## Annotation Tools \n",
    "\n",
    "- **For bounding boxes**: [labelImg](https://github.com/heartexlabs/labelImg), [VGG Image Annotator (VIA)](https://www.robots.ox.ac.uk/~vgg/software/via/) , [CVAT](https://cvat.org/).  \n",
    "- **For segmentation**: [LabelMe](https://github.com/wkentaro/labelme), [VGG Image Annotator (VIA)](https://www.robots.ox.ac.uk/~vgg/software/via/), [CVAT](https://cvat.org/).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce495ad7",
   "metadata": {},
   "source": [
    "## Annotation Formats  \n",
    "\n",
    "Different datasets and frameworks use different annotation formats. Let’s look at the **three most common ones** with examples.  \n",
    "\n",
    "### **COCO Format (JSON)**  \n",
    "\n",
    "- **Supports**: Bounding boxes, segmentation, keypoints  \n",
    "- **Bounding box format**: `[x_min, y_min, width, height]`  \n",
    "- **Widely used in**: Detectron2, MMDetection, COCO dataset  \n",
    "\n",
    "**Example:**  \n",
    "```json\n",
    "{\n",
    "  \"images\": [\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"file_name\": \"cat.jpg\",\n",
    "      \"width\": 800,\n",
    "      \"height\": 600\n",
    "    }\n",
    "  ],\n",
    "  \"annotations\": [\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"image_id\": 1,\n",
    "      \"category_id\": 1,\n",
    "      \"bbox\": [100, 150, 200, 300],\n",
    "      \"area\": 60000,\n",
    "      \"iscrowd\": 0\n",
    "    }\n",
    "  ],\n",
    "  \"categories\": [\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"name\": \"cat\",\n",
    "      \"supercategory\": \"animal\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada5c2b4",
   "metadata": {},
   "source": [
    "### Pascal VOC Format (XML)\n",
    "\n",
    " - **Supports**: Bounding boxes, segmentation masks\n",
    "\n",
    " - **Bounding box format**: `(xmin, ymin, xmax, ymax)`\n",
    "\n",
    " - **Widely used in**: TensorFlow Object Detection API, Pascal VOC dataset\n",
    "\n",
    "**Example**\n",
    "```\n",
    "<annotation>\n",
    "    <folder>images</folder>\n",
    "    <filename>cat.jpg</filename>\n",
    "    <size>\n",
    "        <width>800</width>\n",
    "        <height>600</height>\n",
    "        <depth>3</depth>\n",
    "    </size>\n",
    "    <object>\n",
    "        <name>cat</name>\n",
    "        <pose>Unspecified</pose>\n",
    "        <truncated>0</truncated>\n",
    "        <difficult>0</difficult>\n",
    "        <bndbox>\n",
    "            <xmin>100</xmin>\n",
    "            <ymin>150</ymin>\n",
    "            <xmax>300</xmax>\n",
    "            <ymax>450</ymax>\n",
    "        </bndbox>\n",
    "    </object>\n",
    "</annotation>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70788b25",
   "metadata": {},
   "source": [
    "### YOLO Format (TXT)\n",
    "\n",
    "**Supports**: Bounding boxes only\n",
    "\n",
    "**Bounding box format**: `class_id x_center y_center width height`\n",
    "\n",
    "(all values normalized between `0–1`)\n",
    "\n",
    "**Example**\n",
    "`0 0.25 0.5 0.25 0.5`\n",
    "\n",
    "Explanation (for an image of width 800 and height 600):\n",
    "\n",
    "- 0 → class ID for \"cat\"\n",
    "\n",
    "- x_center = (100 + 200/2) / 800 = 0.25\n",
    "\n",
    "- y_center = (150 + 300/2) / 600 = 0.5\n",
    "\n",
    "- width = 200 / 800 = 0.25\n",
    "\n",
    "- height = 300 / 600 = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bca2cfd",
   "metadata": {},
   "source": [
    "## VGG IMAGE ANNOTATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351295ff",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/nearkyh/via-1.0.5.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67305e58",
   "metadata": {},
   "source": [
    "1. Open the folder via-1.0.5\n",
    "2. Run via.html \n",
    "\n",
    "Follow the demonstration in the lab for simple bbox and segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047098dc",
   "metadata": {},
   "source": [
    "## labelimg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a978a1",
   "metadata": {},
   "source": [
    "If activation scripts are blocked, run the process-scope bypass first:\n",
    "\n",
    "```Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass```\n",
    "\n",
    "Register the venv as Jupyter Kernel\n",
    "\n",
    "```python -m ipykernel install --user --name=cv-lab-venv --display-name 'Python (cv-lab-venv)'```\n",
    "\n",
    "Install pip\n",
    "\n",
    "```python -m ensurepip --upgrade```\n",
    "\n",
    "```python -m pip install --upgrade pip setuptools wheel```\n",
    "\n",
    "Install package labelimg\n",
    "\n",
    "```python -m pip install labelimg```\n",
    "\n",
    "Run labelimg\n",
    "\n",
    "`labelimg`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27ab1a5",
   "metadata": {},
   "source": [
    "Check more on labelimg here: https://pypi.org/project/labelImg/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-lab-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

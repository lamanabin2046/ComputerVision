# -*- coding: utf-8 -*-
"""LaNet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Jn4uNhiiOFTIZaZTWvfePvabsNMWrvBK
"""

# -----------------------------
# Step 1: Import Libraries
# -----------------------------
import tensorflow as tf
from tensorflow.keras import layers, models
import numpy as np
import matplotlib.pyplot as plt

# -----------------------------
# Step 2: Load and Preprocess MNIST
# -----------------------------
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

# Resize to 32x32
x_train = np.pad(x_train, ((0,0),(2,2),(2,2)), 'constant')
x_test = np.pad(x_test, ((0,0),(2,2),(2,2)), 'constant')

# Normalize to [0,1]
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Add channel dimension
x_train = x_train[..., np.newaxis]
x_test = x_test[..., np.newaxis]

# -----------------------------
# Step 3: Define Class-Based LeNet
# -----------------------------
class LeNet(tf.keras.Model):
    def __init__(self, num_classes=10):
        super(LeNet, self).__init__()

        # Convolutional Layers
        self.conv1 = layers.Conv2D(6, (5,5), activation='tanh', padding='same')
        self.pool1 = layers.AveragePooling2D(pool_size=(2,2), strides=2)

        self.conv2 = layers.Conv2D(16, (5,5), activation='tanh')
        self.pool2 = layers.AveragePooling2D(pool_size=(2,2), strides=2)

        self.conv3 = layers.Conv2D(120, (5,5), activation='tanh')

        # Fully Connected Layers
        self.flatten = layers.Flatten()
        self.fc1 = layers.Dense(84, activation='tanh')
        self.fc2 = layers.Dense(num_classes, activation='softmax')

    def call(self, x):
        x = self.conv1(x)
        x = self.pool1(x)
        x = self.conv2(x)
        x = self.pool2(x)
        x = self.conv3(x)
        x = self.flatten(x)
        x = self.fc1(x)
        x = self.fc2(x)
        return x

# -----------------------------
# Step 4: Create and Compile Model
# -----------------------------
lenet_model = LeNet(num_classes=10)
lenet_model.build(input_shape=(None, 32, 32, 1))  # Build the model
lenet_model.compile(optimizer='adam',
                    loss='sparse_categorical_crossentropy',
                    metrics=['accuracy'])

lenet_model.summary()

# -----------------------------
# Step 5: Train the Model
# -----------------------------
history = lenet_model.fit(x_train, y_train,
                          validation_split=0.1,
                          epochs=5,
                          batch_size=128)

# -----------------------------
# Step 6: Evaluate on Test Data
# -----------------------------
test_loss, test_acc = lenet_model.evaluate(x_test, y_test)
print("Test Accuracy:", test_acc)

# -----------------------------
# Step 7: Visualize Predictions (Optional)
# -----------------------------
predictions = lenet_model.predict(x_test[:10])
pred_labels = np.argmax(predictions, axis=1)

plt.figure(figsize=(10,2))
for i in range(10):
    plt.subplot(1,10,i+1)
    plt.imshow(x_test[i].reshape(32,32), cmap='gray')
    plt.title(pred_labels[i])
    plt.axis('off')
plt.show()

